Read Array in reverse order: 
	arr[::-1]

Print the statement in the same line: 
	print(n,end=" ")

Strip and Split:
my_string = "blah, lots  ,  of ,  spaces, here "
[x.strip() for x in my_string.split(',')]


Day1:---------------Theory--------------------------1.Basic Python :Computer science, as it pertains to the problem-solving process itself, is also the study of abstraction. Abstraction allows us to view the problem and solution in such a way as to separate the so-called logical and physical perspectives. procedural abstraction. We do not necessarily know how the square root is being calculated, but we know what the function is called and how to use it.Programming is the process of taking an algorithm and encoding it into a notation, a programming language,All data items in the computer are represented as strings of binary digits. In order to give these strings meaning, we need to have data types. Data types provide an interpretation for this binary data ---------------Abstract Data Type--------------------------An abstract data type,(ADT), is a logical description of how we view the data and the operations that are allowed without regard to how they will be implemented. he idea is that by encapsulating the details of the implementation, we are hiding them from the user’s view. This is called information hiding.class to be a description of what the data look like (the state) and what the data can do (the behavior). -->Data types, assignment, conversion	6/3 = 2.0 (Float)	6//3 = 2 (int)[Integer Division]	2**10 = 1024 (2^10)	'3'+'2' = 32 (String Concatenation)	'90'==90 [False, Comparing string and integer values]Day2:Lists, strings, and tuples are ordered collectionsSets and dictionaries are unordered collections.---------------LIST--------------------------A list is an ordered collection of zero or more references to Python data objects.Lists are heterogeneous, meaning that the data objects need not all be from the same class 	A list can be changed	List = [0,1,True,2.4]	List[1:3] --> [1,True] (Slicing operations)()Inlcudes element from index 1 till index 3 but excluding index 3 value)	myList = [0] * 6 --> [0, 0, 0, 0, 0, 0]	alist.pop()	Removes and returns the last item in a list	alist.pop(i)	Removes and returns the ith item in a list	list(range(5,10))  -->[5, 6, 7, 8, 9]	list(range(5,10,2))-->[5, 7, 9] (skips a element and then prints the value)---------------TUPLE--------------------------	A TUPLE CANNOT BE CHANGED(IMMUTABLE)	Tuple: (2,True,4.96)	Tuple[1]=False  --> Error---------------SET--------------------------	A set is an unordered collection and Sets do not allow duplicates 	Set : {3,6,9}	setA.union(setB) <--> setA | setB	setA.intersection(setB) <--> setA & setB	setA.difference(setB) <--> setA - setB	setA.issubset(setB	)	2 types of control structures: Iterative(for, while) and Selectionwhile statement repeats a body of code as long as a condition is true. for statement can be used to iterate over the members of a collection, so long as the collection is a sequence---------------RECURSION---------------------------All recursive algorithms must have a base case.-A recursive algorithm must change its state and make progress toward the base case.-A recursive algorithm must call itself (recursively).BASE CASE:A branch of the conditional statement in a recursive function that does not give rise to further recursive calls.exception: An error that occurs at runtime.handle an exception: To prevent an exception from terminating a program by wrapping the block of code in a try / except construct.infinite recursion: A function that calls itself recursively without ever reaching the base case. Eventually, an infinite recursion causes a runtime erroFibonacci Recursionint fib(int num):	if num <= 0:		return 0	elif num == 1:		return 1	else:		return fib(n-1)+fib(n-2)Day 3:To implement an abstract data type, we will do so with a new class.Class to be a description of what the data look like (the state) and what the data can do (the behavior). "self" is a special parameter that will always be used as a reference back to the object itself. It must always be the first formal parameter; however, it will never be given an actual parameter value upon invocation __str__, is the method to convert an object into a string. The default implementation for this method is to return the instance address string Two different objects with the same numerators and denominators would not be equal under this implementation. This is called shallow equalityWe can create deep equality (see Figure 7)–equality by the same value, not the same reference–by overriding the __eq__ method.The __eq__ method compares two objects and returns True if their values are the same, False otherwise.Inheritance is the ability for one class to be related to another class . Python child classes can inherit characteristic data and behavior from a parent class. These classes are often referred to as subclasses and superclasses.		Collections Sequentials 			Non SequentialsLists,String,Tuple		Dictionarythe list IS-A sequential ------------Searching & Sorting---------------Sequential Search (Complexity : O(n) [For ordered and Unordered list])def sequentialSearch(alist, item):	    pos = 0	    found = False		    while pos < len(alist) and not found:	        if alist[pos] == item:	            found = True			else:				pos = pos+1		    return found		testlist = [1, 2, 32, 8, 17, 19, 42, 13, 0]	print(sequentialSearch(testlist, 3))	print(sequentialSearch(testlist, 13))	Binary Search: Complexity: O(log n)def binarySearch(alist, item):	    first = 0	    last = len(alist)-1	    found = False		    while first<=last and not found:	        midpoint = (first + last)//2	        if alist[midpoint] == item:	            found = True	        else:	            if item < alist[midpoint]:	                last = midpoint-1	            else:	                first = midpoint+1		    return foundDay 4:Algorithm is a generic, step-by-step list of instructions for solving a problem. It is a method for solving any instance of the problem such that given a particular input, the algorithm produces the desired result.Algorithm analysis is concerned with comparing algorithms based upon the amount of computing resources that each algorithm usesOne way is to consider the amount of space or memory an algorithm requires to solve the problemSecond is we can analyze and compare algorithms based on the amount of time they require to execute. This measure is sometimes referred to as the “execution time” or “running time” of the algorithm.Execution time for an algorithm can be expressed as the number of steps required to solve the problem. he order of magnitude function describes the part of T(n) that increases the fastest as the value of n increases. Order of magnitude is often called Big-O notation (for “order”) and written as O(f(n)). It provides a useful approximation to the actual number of steps in the computation. The function f(n) provides a simple representation of the dominant part of the original T(n).f(n)	Name1	Constantlogn	Logarithmicn	Linearnlogn	Log Linearn2	Quadraticn3	Cubic2^n	Exponential------------------Dictionary------------------------------Dictionaries differ from lists in that you can access items in a dictionary by a key rather than a position. operation	Big-O Efficiencycopy	O(n)get item	O(1)set item	O(1)delete item	O(1)contains (in)	O(1)iteration	O(n)ListsOperation	Big-O Efficiencyindex []	O(1)index assignment	O(1)append		O(1)pop()		O(1)pop(i)		O(n)insert(i,item)	O(n)del operator	O(n)iteration	O(n)contains (in)	O(n)get slice [x:y]	O(k)del slice	O(n)set slice	O(n+k)reverse		O(n)concatenate	O(k)sort		O(n log n)multiply	O(nk)One string is an anagram of another if the second is simply a rearrangement of the first. For example, 'heart' and 'earth' are anagrams. The strings 'python' and 'typhon' are anagrams as well. Solutions: 1.Checking Off 2. Sort & Compare 3.Brute Force 4. Count & CompareBubble Sort:Each pass through the list places the next largest value in its proper place. In essence, each item “bubbles” up to the location where it belongs.A bubble sort can be modified to stop early if it finds that the list has become sorted. This means that for lists that require just a few passes, a bubble sort may have an advantage in that it will recognize the sorted list and stop. which is often referred to as the short bubble.	Selection Sort :The selection sort improves on the bubble sort by making only one exchange for every pass through the list.A bubble sort, a selection sort, and an insertion sort are O(n^2) algorithms.Shell sort:The shell sort, sometimes called the “diminishing increment sort,” improves on the insertion sort by breaking the original list into a number of smaller sublists, each of which is sorted using an insertion sort. A shell sort improves on the insertion sort by sorting incremental sublists. It falls between O(n) and O(n2).(O(n^[3/2]))--A merge sort is O(nlogn), but requires additional space for the merging process. divide and conquer strategy.  recursive algorithm that continually splits a list in half. Merging is the process of taking two smaller sorted lists and combining them together into a single, sorted, new list--A quick sort is O(nlogn), but may degrade to O(n2) if the split points are not near the middle of the list. It does not require additional space.The actual position where the pivot value belongs in the final sorted list, commonly called the split point, will be used to divide the list for subsequent calls to the quick sort.BubbleSort: Complexity: O(n^2)def bubbleSort(alist):    for passnum in range(len(alist)-1,0,-1):        for i in range(passnum):            if alist[i]>alist[i+1]:                temp = alist[i]                alist[i] = alist[i+1]                alist[i+1] = tempalist = [54,26,93,17,77,31,44,55,20]bubbleSort(alist)print(alist)SelectionSort: Complexity: O(n^2)def selectionSort(alist):   for fillslot in range(len(alist)-1,0,-1):       positionOfMax=0       for location in range(1,fillslot+1):           if alist[location]>alist[positionOfMax]:               positionOfMax = location       temp = alist[fillslot]       alist[fillslot] = alist[positionOfMax]       alist[positionOfMax] = tempalist = [54,26,93,17,77,31,44,55,20]selectionSort(alist)print(alist)Merge Sort : Complexity : O(n*log(n))def mergeSort(alist):    print("Splitting ",alist)    if len(alist)>1:        mid = len(alist)//2        lefthalf = alist[:mid]        righthalf = alist[mid:]        mergeSort(lefthalf)        mergeSort(righthalf)        i=0        j=0        k=0        while i < len(lefthalf) and j < len(righthalf):            if lefthalf[i] < righthalf[j]:                alist[k]=lefthalf[i]                i=i+1            else:                alist[k]=righthalf[j]                j=j+1            k=k+1        while i < len(lefthalf):            alist[k]=lefthalf[i]            i=i+1            k=k+1        while j < len(righthalf):            alist[k]=righthalf[j]            j=j+1            k=k+1    print("Merging ",alist)alist = [54,26,93,17,77,31,44,55,20]mergeSort(alist)print(alist)------------------Stack--------------------------Day 5:-A stack (sometimes called a “push-down stack”) is an ordered collection of items where the addition of new items and the removal of existing items always takes place at the same end. This end is commonly referred to as the “top.” The end opposite the top is known as the “base.”-The most recently added item is the one that is in position to be removed first. This ordering principle is sometimes called LIFO, last-in first-out. Operations:Stack()push(item)pop()peek()isEmpty()size()Balanced parentheses means that each opening symbol has a corresponding closing symbol and the pairs of parentheses are properly nested. infix : the operator is in between the two operands that it is working on.Prefix expression notation requires that all operators precede the two operands that they work on. Postfix, on the other hand, requires that its operators come after the corresponding operands.1035*164-/+A queue is an ordered collection of items where the addition of new items happens at one end, called the “rear,” and the removal of existing items occurs at the other end, commonly called the “front.” The item that has been in the collection the longest is at the front. This ordering principle is sometimes called FIFO, first-in first-out. It is also known as “first-come first-served.”Day 6:A list is a collection of items where each item holds a relative position with respect to the others.Node Class :The basic building block for the linked list implementation is the node. Each node object must hold at least two pieces of information. First, the node must contain the list item itself. We will call this the data field of the node. In addition, each node must hold a reference to the next node.Two references are equal if they both refer to the same object.------------------GRAPH--------------------------Day 9:A vertex (also called a “node”) is a fundamental part of a graph. It can have a name, which we will call the “key.” Adittional Info : PayloadAn edge (also called an “arc”) is another fundamental part of a graph. An edge connects two vertices to show that there is a relationship between them.Edges may be one-way or two-way. If the edges in a graph are all one-way, we say that the graph is a directed graph, or a digraphWeight : Edges may be weighted to show that there is a cost to go from one vertex to another. A graph can be represented by G where G=(V,E). For the graph G, VV is a set of vertices and EE is a set of edges. Each edge is a tuple (v,w) where w,v∈V PathA path in a graph is a sequence of vertices that are connected by edgeshe unweighted path length is the number of edges in the path, specifically n−1. The weighted path length is the sum of the weights of all the edges in the path. CycleA cycle in a directed graph is a path that starts and ends at the same vertex. . A graph with no cycles is called an acyclic graph. A directed graph with no cycles is called a directed acyclic graph or a DAG.-------------Adjacency Matrix----------------One of the easiest ways to implement a graph is to use a two-dimensional matrix. In this matrix implementation, each of the rows and columns represent a vertex in the graph. The value that is stored in the cell at the intersection of row v and column w indicates if there is an edge from vertex v to vertex w.-Most of the cells are empty we say that this matrix is “sparse.”-Since there is one row and one column for every vertex in the graph, the number of edges required to fill the matrix is |V|^2.-------------Adjacency List----------------In an adjacency list implementation we keep a master list of all the vertices in the Graph object and then each vertex object in the graph maintains a list of the other vertices that it is connected to. In our implementation of the Vertex class we will use a dictionary rather than a listwhere the dictionary keys are the vertices, and the values are the weights.BFS : O(V+E)def findShortestPath(start, end):    """    Find the shortest path, if one exists, between a start and end vertex    :param start (Vertex): the start vertex    :param end (Vertex): the destination vertex    :return: A list of Vertex objects from start to end, if a path exists,        otherwise None    """    # Using a queue as the dispenser type will result in a breadth first    # search    queue = []    queue.append(start)         # prime the queue with the start vertex    # The predecessor dictionary maps the current Vertex object to its    # immediate predecessor.  This collection serves as both a visited    # construct, as well as a way to find the path    predecessors = {}    predecessors[start] = None  # add the start vertex with no predecessor    # Loop until either the queue is empty, or the end vertex is encountered    while len(queue) > 0:        current = queue.pop(0)        if current == end:            break        for neighbor in current.getConnections():            if neighbor not in predecessors:        # if neighbor unvisited                predecessors[neighbor] = current    # map neighbor to current                queue.append(neighbor)              # enqueue the neighbor    # If the end vertex is in predecessors a path was found    if end in predecessors:        path = []        current = end        while current != start:              # loop backwards from end to start            path.insert(0, current)          # prepend current to the path list            current = predecessors[current]  # move to the predecessor        path.insert(0, start)        return path    else:        return None        from pythonds.graphs import Graph, Vertexfrom pythonds.basic import Queuedef bfs(g,start):  start.setDistance(0)  start.setPred(None)  vertQueue = Queue()  vertQueue.enqueue(start)  while (vertQueue.size() > 0):    currentVert = vertQueue.dequeue()    for nbr in currentVert.getConnections():      if (nbr.getColor() == 'white'):        nbr.setColor('gray')        nbr.setDistance(currentVert.getDistance() + 1)        nbr.setPred(currentVert)        vertQueue.enqueue(nbr)    currentVert.setColor('black')DFS:-------------Butler Code-------------------def __findPathDFS(current, end, visited):    """    Private recursive helper function that finds the path, if one exists,    from the current vertex to the end vertex    :param current (Vertex): The current vertex in the traversal    :param end (Vertex): The destination vertex    :param visited (set of Vertex): the vertices already visited    :return: A list of Vertex objects from start to end, if a path exists,        otherwise None    """    # A successful base case is when we traverse to the end vertex.  In this    # case, wrap it in a list and return it to the caller to construct the    # full path    if current == end:        return [current]    for neighbor in current.getConnections():        if neighbor not in visited:            visited.add(neighbor)            path = __findPathDFS(neighbor, end, visited)            # If the path is not None, current is part of the solution path,            # so add it to the front of the path list and return it            if path != None:                path.insert(0, current)                return path    # No path was found, so pass back None    return Nonedef findPathDFS(start, end):    """    Find a path, if one exists, from a start to end vertex.    :param start (Vertex): the start vertex    :param end (Vertex): the destination vertex    :return: A list of Vertex objects from start to end, if a path exists,        otherwise None    """    visited = set()    visited.add(start)    return __findPathDFS(start, end, visited)from pythonds.graphs import Graphclass DFSGraph(Graph):    def __init__(self):        super().__init__()        self.time = 0    def dfs(self):        for aVertex in self:            aVertex.setColor('white')            aVertex.setPred(-1)        for aVertex in self:            if aVertex.getColor() == 'white':                self.dfsvisit(aVertex)    def dfsvisit(self,startVertex):        startVertex.setColor('gray')        self.time += 1        startVertex.setDiscovery(self.time)        for nextVertex in startVertex.getConnections():            if nextVertex.getColor() == 'white':                nextVertex.setPred(startVertex)                self.dfsvisit(nextVertex)        startVertex.setColor('black')        self.time += 1        startVertex.setFinish(self.time)-------------Hashing:---------------------For a successful search using open addressing with linear probing, the average number of comparisons is approximately 1/2(1+1/1−λ) and an unsuccessful search gives 1/2(1+(1/1−λ)^2) If we are using chaining,the average number of comparisons is 1+λ/2 for the successful case, and simply λ comparisons if the search is unsuccessful.Dijkstra's Algo : O((V+E)log(V)).The algorithm we are going to use to determine the shortest path is called “Dijkstra’s algorithm.” Dijkstra’s algorithm is an iterative algorithm that provides us with the shortest path from one particular starting node to all other nodes in the graphfrom pythonds.graphs import PriorityQueue, Graph, Vertexdef dijkstra(aGraph,start):    pq = PriorityQueue()    start.setDistance(0)    pq.buildHeap([(v.getDistance(),v) for v in aGraph])    while not pq.isEmpty():        currentVert = pq.delMin()        for nextVert in currentVert.getConnections():            newDist = currentVert.getDistance() \                    + currentVert.getWeight(nextVert)            if newDist < nextVert.getDistance():                nextVert.setDistance( newDist )                nextVert.setPred(currentVert)                pq.decreaseKey(nextVert,newDist)Day 10:in a priority queue the logical order of items inside a queue is determined by their priority. The highest priority items are at the front of the queue and the lowest priority items are at the back.However, inserting into a list is O(n) and sorting a list is O(nlogn).The classic way to implement a priority queue is using a data structure called a binary heap. A binary heap will allow us both enqueue and dequeue items in O(logn).The binary heap has two common variations: the min heap, in which the smallest key is always at the front, and the max heap, in which the largest key value is always at the front.In our heap implementation we keep the tree balanced by creating a complete binary tree.A complete binary tree is a tree in which each level has all of its nodes.Because the tree is complete, the left child of a parent (at position pp) is the node that is found in position 2p in the list. Similarly, the right child of the parent is at position 2p+1Given that a node is at position n in the list, the parent is at position n/2.percUp method, which percolates a new item as far up in the tree as it needs to go to maintain the heap property.A hash table is a collection of items which are stored in such a way as to make it easy to find them later. Each position of the hash table, often called a slot, can hold an item and is named by an integer value starting at 0.Ex: Suppose 6 of the 11 slots are now occupied.This is referred to as the load factor, and is commonly denoted by λ=numberofitems/tablesize.For this example, λ=6/11According to the hash function, two or more items would need to be in the same slot. This is referred to as a collision(Clash)Given a collection of items, a hash function that maps each item into a unique slot is referred to as a perfect hash functionMinimize collisionEasy to ComputeEvenly distribute thr itemsDifferent Ways:Increase the table sizeFolding method : Dividing the item into equal size and then add all of them. result value % table sizeMid Square method : square the number and extract middle two digits. Result value % table sizehash functions for character based string:get ordinal values of each characterAdd all of themResult value % table sizeWhen two items hash to the same slot, we must have a systematic method for placing the second item in the hash table. This process is called collision resolution.  A simple way to do this is to start at the original hash value position and then move in a sequential manner through the slots until we encounter the first slot that is empty. Note that we may need to go back to the first slot (circularly) to cover the entire hash table. This collision resolution process is referred to as open addressing in that it tries to find the next open slot or address in the hash table. By systematically visiting each slot one at a time, we are performing an open addressing technique called linear probing.A disadvantage to linear probing is the tendency for clustering; items become clustered in the table. This means that if many collisions occur at the same hash value, a number of surrounding slots will be filled by the linear probing resolution. quadratic probing, we use a rehash function that increments the hash value by 1, 3, 5, 7, 9, and so on. This means that if the first hash value is h, the successive values are h+1, h+4, h+9, h+16, and so on. In other words, quadratic probing uses a skip consisting of successive perfect squares. Chaining allows many items to exist at the same location in the hash table. When collisions happen, the item is still placed in the proper slot of the hash table.class BinaryTree:    def __init__(self,rootObj):        self.key = rootObj        self.leftChild = None        self.rightChild = Nonedef insertLeft(self,newNode):    if self.leftChild == None:        self.leftChild = BinaryTree(newNode)    else:        t = BinaryTree(newNode)        t.leftChild = self.leftChild        self.leftChild = tdef insertRight(self,newNode):    if self.rightChild == None:        self.rightChild = BinaryTree(newNode)    else:        t = BinaryTree(newNode)        t.rightChild = self.rightChild        self.rightChild = tdef getRightChild(self):    return self.rightChilddef getLeftChild(self):    return self.leftChilddef setRootVal(self,obj):    self.key = objdef getRootVal(self):    return self.keyTree Traversal:def preorder(self):    print(self.key)    if self.leftChild:        self.leftChild.preorder()    if self.rightChild:        self.rightChild.preorder()def postorder(tree):    if tree != None:        postorder(tree.getLeftChild())        postorder(tree.getRightChild())        print(tree.getRootVal())def inorder(tree):  if tree != None:      inorder(tree.getLeftChild())      print(tree.getRootVal())      inorder(tree.getRightChild())